## 一、存储过程(有序插入)

>测试环境：
>
>内存：4G
>
>CPU：Intel(R) Core(TM) i5-4590 CPU @ 3.30GHz
>
>mysql：5.7.29
>
>运行环境：docker swarm
>
>mysql的binlog日志没有开，autocommit关闭状态

### 1.1 单个事务多个Insert into语句的方式

#### 测试情况

| 每次事务提交的insert数量 | 执行时间 | 执行事务次数 |
| ------------------------ | -------- | ------------ |
| 1                        | 100.984s | 1000000      |
| 2                        | 68.951s  | 500000       |
| 5                        | 45.515s  | 200000       |
| 10                       | 38.573s  | 100000       |
| 50                       | 31.555s  | 20000        |
| 100                      | 30.137s  | 10000        |
| 500                      | 28.745s  | 2000         |
| 1000                     | 28.513s  | 1000         |
| 1500                     | 28.441s  | 667          |
| 1800                     | 28.348s  | 556          |
| 2000                     | 28.439s  | 500          |
| 5000                     | 28.296s  | 200          |
| 10000                    | 28.23s   | 100          |
| 100000                   | 28.01s   | 10           |
| 1000000                  | 28.07s   | 1            |

#### 存储过程代码

```sql
CREATE DEFINER=`mail`@`%` PROCEDURE `order_data_init3`( IN `batch_num` INT )
BEGIN
DECLARE
	i INT;
DECLARE
	total_num INT DEFAULT 1000000;

SET i = 0;
START TRANSACTION;
WHILE
	i < total_num DO
INSERT INTO order_info ( order_code, order_status, create_time, payment_time, delivery_time, expected_time, arrive_time, complete_time, merchant_id, merchant_name, customer_id, customer_name )
VALUES
	(
		concat( '234234023423', i ),
		'1',
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		i,
		concat( 'merchant_name', i ),
		i,
		concat( 'customer_name', i ) 
	);
IF
	i % batch_num = 0 THEN
		COMMIT;
	START TRANSACTION;
END IF;
SET i = i + 1;
END WHILE;
COMMIT;
END
```

### 1.2 单个事务一个insert into xx values (),(),()...的方式

#### 测试情况

| insert into 后面的数据量 | 执行时间 | 执行事务次数 |
| ------------------------ | -------- | ------------ |
| 50                       | 27.63s   | 20000        |
| 100                      | 26.181s  | 10000        |
| 500                      | 27.456s  | 2000         |
| 1000                     | 31.954s  | 1000         |
| 1500                     | 36.244s  | 667          |
| 2000                     | 41.674s  | 500          |
| 5000                     | 67.447s  | 200          |
| 10000                    | 109.289s | 100          |
| 1000000                  | 8.601s   | 1            |

#### 存储过程代码

```sql
CREATE DEFINER=`mail`@`%` PROCEDURE `order_data_batch_init2`( IN `batch_num` INT )
BEGIN
DECLARE
	i INT;
DECLARE
	num INT;
DECLARE
	SQL_FOR_INSERT LONGBLOB;

SET num = 0;

SET i = 0;
WHILE
	i < 1000000 DO
IF
i % batch_num = 0 THEN
START TRANSACTION;

SET SQL_FOR_INSERT = concat( 'insert into order_info(order_code, order_status,', 'create_time, payment_time, delivery_time,', 'expected_time, arrive_time, complete_time,', 'merchant_id, merchant_name, customer_id,', 'customer_name) values ' );

SET SQL_FOR_INSERT = concat(
	SQL_FOR_INSERT,
	'(',
	concat( '''', '234234023423', i, '''' ),
	',',
	'''1''',
	',',
	REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
	',',
	REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
	',',
	REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
	',',
	REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
	',',
	REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
	',',
	REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
	',',
	concat( '''', i, '''' ),
	',',
	concat( '''', 'merchant_name', i, '''' ),
	',',
	concat( '''', i, '''' ),
	',',
	concat( '''', 'customer_name', i, '''' ),
	')' 
);
ELSE 
	SET SQL_FOR_INSERT = concat(
		SQL_FOR_INSERT,
		', (',
		concat( '''', '234234023423', i, '''' ),
		',',
		'''1''',
		',',
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		',',
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		',',
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		',',
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		',',
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		',',
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		',',
		concat( '''', i, '''' ),
		',',
		concat( '''', 'merchant_name', i, '''' ),
		',',
		concat( '''', i, '''' ),
		',',
		concat( '''', 'customer_name', i, '''' ),
		')' 
	);

END IF;
IF
	( ( i + 1 ) % batch_num = 0 ) THEN
		
		SET @SQL = SQL_FOR_INSERT;
	PREPARE stmt 
	FROM
		@SQL;-- 预处理动态sql语句
	EXECUTE stmt;-- 执行sql语句
	DEALLOCATE PREPARE stmt;-- 释放prepare
	COMMIT;
	
	SET num = num + 1;
	
	ELSEIF ( i = 999999 ) THEN
	
	SET @SQL = SQL_FOR_INSERT;
	PREPARE stmt 
	FROM
		@SQL;-- 预处理动态sql语句
	EXECUTE stmt;-- 执行sql语句
	DEALLOCATE PREPARE stmt;-- 释放prepare
	COMMIT;
	
	SET num = num + 1;
	
END IF;

SET i = i + 1;

END WHILE;
SELECT
	num;

END
```

### 1.3 总结

从结果来看：

批量提交多条insert into 语句 要比 insert into values 多个值 效率要高；

- 在理论环境下，在同一个事务中批量提交的越多，性能普遍较好（减少了创建事务的开销，但是会有触发log_buffer刷盘的开销），批量提交的时候需要注意控制事务的大小，事务太大，强制buffer flush的过程中，如果发生日志文件写满了，还没有写完，这样会导致日志不能切换，Mysql就会hang住。（这个时候可以根据文件修改时间来判断日志文件的旋转频率，旋转频率太频繁，说明日志文件较小）。
- insert into values (),()..如果values后面的值过多，会增加语法解析的时间，影响性能（复杂对sql的解析引擎不友好）。

## 二、批量插入：程序插入
> 框架使用：springboot、hikari
> 网络情况：局域网、100M

### JPA方式

#### 准备工作：

1. 数据连接中加上 logger=Slf4JLogger&profileSQL=true，用来显示 MySQL 执行的 SQL 日志，例如：

   ```yaml
   url: jdbc:mysql://ip:端口/dbname?useUnicode=true&characterEncoding=utf8&useSSL=false&logger=Slf4JLogger&profileSQL=true
   ```

2. 打开 Spring 的事务处理日志，用来观察事务的执行过程

   ```yaml
   logging:
     level:
       org:
         springframework:
           orm:
             jpa: DEBUG
           transaction: trace
         hibernate:
           engine:
             transaction:
               internal:
                 TransactionImpl: debug
           resource:
             jdbc: trace
       com:
         zaxxer:
           hikari: DEBUG
   ```

   ![image-20201203094208870](.\img\jpa-tx-logger.png)

#### 结果

- 单线程情况下，一个事务提交1000000条耗时：3_100_944ms
- 单线程情况下，一个事务提交1000条，共提交1000000条, 耗时:3_968_880ms
- 单线程情况下，一个事务提交1条，共提交1000000条, 耗时:5_538_787ms

#### 总结：

jpa得插入性能奇差无比，每次save时，先要对对象做存在性检查，在进行插入。

从源码上看批量插入也是进行多次的save操作

```java
@Transactional
public <S extends T> List<S> saveAll(Iterable<S> entities) {
    Assert.notNull(entities, "Entities must not be null!");
    List<S> result = new ArrayList();
    Iterator var3 = entities.iterator();

    while(var3.hasNext()) {
        S entity = var3.next();
        result.add(this.save(entity));
    }
    return result;
}
```

### springjdbc方式

#### 准备工作

1. datasource上增加rewriteBatchedStatements=true来开启批量写入

#### 结果

| 每次事务提交的insert数量 | 执行时间 | 执行事务次数 |
| ------------------------ | -------- | ------------ |
| 1000000                  | 41483ms  | 1            |
| 1000                     | 24172ms  | 1000         |
| 5000                     | 21888ms  | 200          |
| 10000                    | 25207ms  | 100          |



## 三、参考资料：
https://www.cnblogs.com/zhiqian-ali/p/4976989.html 【insert批量插入优化方案】

https://blog.csdn.net/bohu83/article/details/82903976?utm_source=blogxgwz1 【MySQL · 源码分析 · 一条insert语句的执行过程】

https://yq.aliyun.com/articles/131279 【 **Mysql 批量insert 性能测试** 】

https://www.imooc.com/wenda/detail/582058【多个INSERT语句与具有多个VALUES的单个INSERT】

https://blog.csdn.net/cke63021/article/details/100222034【mysql innodb_log_file_size 和innodb_log_buffer_size参数】
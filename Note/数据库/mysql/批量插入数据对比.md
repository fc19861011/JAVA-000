## 1、存储过程(有序插入)

>binlog日志没有开

### 1.1 逐条插入

- 插入前清空数据表，插入10000条数据共用时：26.754s

```sql
CREATE DEFINER=`mail`@`%` PROCEDURE `order_data_init`( )
BEGIN
DECLARE
	i INT;
DECLARE
	total_num INT DEFAULT 1000000;

SET i = 0;
START TRANSACTION;
WHILE
	i < total_num DO
INSERT INTO order_info ( order_code, order_status, create_time, payment_time, delivery_time, expected_time, arrive_time, complete_time, merchant_id, merchant_name, customer_id, customer_name )
VALUES
	(
		concat( '234234023423', i ),
		'1',
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		i,
		concat( 'merchant_name', i ),
		i,
		concat( 'customer_name', i ) 
	);
SET i = i + 1;
END WHILE;
COMMIT;
END
```

- 把事务放到while中开启、提交，插入前清空数据表，插入10000条数据共用时：97.675s

```sql
CREATE DEFINER=`mail`@`%` PROCEDURE `order_data_init2`( )
BEGIN
DECLARE
	i INT;
DECLARE
	total_num INT DEFAULT 1000000;

SET i = 0;
WHILE
	i < total_num DO
START TRANSACTION;
INSERT INTO order_info ( order_code, order_status, create_time, payment_time, delivery_time, expected_time, arrive_time, complete_time, merchant_id, merchant_name, customer_id, customer_name )
VALUES
	(
		concat( '234234023423', i ),
		'1',
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		i,
		concat( 'merchant_name', i ),
		i,
		concat( 'customer_name', i ) 
	);
COMMIT;
SET i = i + 1;
END WHILE;
END
```

每执行1500条，提交事务，耗时：28.441s

1700：28.462s

1800：28.348s

1900：28.47s

2000：28.439s

每执行3000条，提交事务，耗时：

1000： 28.454s



2300：28.426s

### 1.2 批量提交

```sql
CREATE DEFINER = `mail` @`%` PROCEDURE `order_data_batch_init` ( IN `batch_num` INT ) BEGIN
DECLARE
	i INT;
DECLARE
	num INT;
DECLARE
	SQL_FOR_INSERT LONGBLOB;

SET num = 0;

SET i = 0;
WHILE
	i < 1000000 DO
IF
i % batch_num = 0 THEN
START TRANSACTION;

SET SQL_FOR_INSERT = concat( 'insert into order_info(order_code, order_status,', 'create_time, payment_time, delivery_time,', 'expected_time, arrive_time, complete_time,', 'merchant_id, merchant_name, customer_id,', 'customer_name) values ' );

SET SQL_FOR_INSERT = concat(
	SQL_FOR_INSERT,
	'(',
	concat( '''', '234234023423', i, '''' ),
	',',
	'''1''',
	',',
	REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
	',',
	REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
	',',
	REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
	',',
	REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
	',',
	REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
	',',
	REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
	',',
	concat( '''', i, '''' ),
	',',
	concat( '''', 'merchant_name', i, '''' ),
	',',
	concat( '''', i, '''' ),
	',',
	concat( '''', 'customer_name', i, '''' ),
	')' 
);
ELSE 
	SET SQL_FOR_INSERT = concat(
		SQL_FOR_INSERT,
		', (',
		concat( '''', '234234023423', i, '''' ),
		',',
		'''1''',
		',',
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		',',
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		',',
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		',',
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		',',
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		',',
		REPLACE ( unix_timestamp( CURRENT_TIMESTAMP ( 3 ) ), '.', '' ),
		',',
		concat( '''', i, '''' ),
		',',
		concat( '''', 'merchant_name', i, '''' ),
		',',
		concat( '''', i, '''' ),
		',',
		concat( '''', 'customer_name', i, '''' ),
		')' 
	);

END IF;
IF
	( ( i + 1 ) % batch_num = 0 ) THEN
		
		SET @SQL = SQL_FOR_INSERT;
	PREPARE stmt 
	FROM
		@SQL;-- 预处理动态sql语句
	EXECUTE stmt;-- 执行sql语句
	DEALLOCATE PREPARE stmt;-- 释放prepare
	COMMIT;
	
	SET num = num + 1;
	
	ELSEIF ( i = 999999 ) THEN
	
	SET @SQL = SQL_FOR_INSERT;
	PREPARE stmt 
	FROM
		@SQL;-- 预处理动态sql语句
	EXECUTE stmt;-- 执行sql语句
	DEALLOCATE PREPARE stmt;-- 释放prepare
	COMMIT;
	
	SET num = num + 1;
	
END IF;

SET i = i + 1;

END WHILE;
SELECT
	num;

END
```

每次提交50条，插入前清空数据表，插入10000条数据共用时：27.63s

每次提交100条，插入前清空数据表，插入10000条数据共用时： 26.181s

每次提交500条，插入前清空数据表，插入10000条数据共用时： 27.456s

每次提交1000条 ，插入前清空数据表，插入10000条数据共用时：31.954s

每次提交1500条 ，插入前清空数据表，插入10000条数据共用时：36.244s

每次提交2000条 ，插入前清空数据表，插入10000条数据共用时：41.674s

每次提交5000条 ，插入前清空数据表，插入10000条数据共用时：67.447s

每次提交10000条 ，插入前清空数据表，插入10000条数据共用时：109.098s

## 2、程序提交

### 2.1 单条提交

### 2.2 批量提交



总结：

事务的开销

redo日志的刷盘

实测：innodb_flush_log_at_trx_commit=2和innodb_flush_log_at_trx_commit=1在存储过程中批量插入时，性能相近

默认redo buffer大小8m，单挑Insert语句大概2.2k，这样8M大约可以存3000条左右的单条Insert 语句，

insert into values (),(),() 语法编译耗时较长， 执行计划 无法复用。

根据：redo日志刷盘的规则中的 当`log buffer`中已经使用的内存超过一半时  将会刷盘，那么设定批量提交1500条理论效果应该最好

网络io的损耗

参考资料：
https://www.cnblogs.com/zhiqian-ali/p/4976989.html 【insert批量插入优化方案】

https://blog.csdn.net/bohu83/article/details/82903976?utm_source=blogxgwz1 【MySQL · 源码分析 · 一条insert语句的执行过程】

https://yq.aliyun.com/articles/131279 【 **Mysql 批量insert 性能测试** 】

https://www.imooc.com/wenda/detail/582058